#!/bin/bash
# CannaSignal: End-to-End Scrape and Ingest Script
# 
# Usage: ./scrape-and-ingest.sh [retailer-slug]
# Example: ./scrape-and-ingest.sh housing-works-cannabis-co
#
# Environment variables:
#   CDP_SECRET - Browser worker authentication
#   CONVEX_DEPLOY_KEY - Convex deploy key (optional, has default)

set -e

# Configuration
CONVEX_URL="https://quick-weasel-225.convex.cloud"
CONVEX_DEPLOY_KEY="${CONVEX_DEPLOY_KEY:-dev:quick-weasel-225|eyJ2MiI6IjBmMDI3MmFiM2MwYjRkNmE5MDY1YzI5MDI5ZDA0YmEyIn0=}"
BROWSER_WORKER_URL="https://cannasignal-browser.prtl.workers.dev"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DATA_DIR="$SCRIPT_DIR/../data/test-scrapes"

# Retailer mappings
declare -A RETAILERS
RETAILERS["housing-works-cannabis-co"]="jx74rzzged5ezfcq6hnwky9pqh818nt2"
RETAILERS["the-cannabist-brooklyn"]="jx797eyczm86jc6aqpg3ex4zwx818rfa"
RETAILERS["smacked-village"]="jx7dmad9mn97367tx33vfwbs61819vxq"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"
}

error() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] âŒ ERROR: $*" >&2
}

# Ensure data directory exists
mkdir -p "$DATA_DIR"

# Get retailer slug from argument or scrape all
SLUG="${1:-all}"

if [ "$SLUG" = "all" ]; then
    SLUGS=("housing-works-cannabis-co" "the-cannabist-brooklyn" "smacked-village")
else
    SLUGS=("$SLUG")
fi

BATCH_ID="batch-$(date +%Y%m%d-%H%M%S)"
log "ğŸŒ¿ CannaSignal Scrape Pipeline"
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log "Batch ID: $BATCH_ID"
log "Retailers: ${SLUGS[*]}"
log ""

# Build results array
RESULTS="["
FIRST=true

for CURRENT_SLUG in "${SLUGS[@]}"; do
    RETAILER_ID="${RETAILERS[$CURRENT_SLUG]}"
    
    if [ -z "$RETAILER_ID" ]; then
        error "Unknown retailer: $CURRENT_SLUG"
        continue
    fi
    
    log "ğŸ“ Processing: $CURRENT_SLUG"
    
    # Try to scrape via browser worker
    SCRAPE_FILE="$DATA_DIR/${CURRENT_SLUG}-$(date +%Y%m%d).json"
    
    if [ -n "$CDP_SECRET" ]; then
        log "   Fetching from browser worker..."
        SCRAPE_RESULT=$(curl -s --max-time 120 \
            "${BROWSER_WORKER_URL}/menu?url=https://dutchie.com/dispensary/${CURRENT_SLUG}&secret=${CDP_SECRET}" \
            2>/dev/null || echo '{"success":false,"error":"curl failed"}')
        
        echo "$SCRAPE_RESULT" > "$SCRAPE_FILE"
        
        # Check for Cloudflare block or empty products
        if echo "$SCRAPE_RESULT" | grep -q '"retailer":"Attention Required'; then
            log "   âš ï¸ Cloudflare blocked - using mock data"
            USE_MOCK=true
        elif echo "$SCRAPE_RESULT" | grep -q '"productCount":0'; then
            log "   âš ï¸ No products found - using mock data"
            USE_MOCK=true
        else
            PRODUCT_COUNT=$(echo "$SCRAPE_RESULT" | jq -r '.productCount // 0')
            if [ "$PRODUCT_COUNT" -gt 0 ]; then
                log "   âœ“ Scraped $PRODUCT_COUNT products"
                USE_MOCK=false
            else
                USE_MOCK=true
            fi
        fi
    else
        log "   âš ï¸ No CDP_SECRET - using mock data"
        USE_MOCK=true
    fi
    
    # Generate ingestion payload
    TIMESTAMP=$(date +%s000)
    SOURCE_URL="https://dutchie.com/dispensary/${CURRENT_SLUG}"
    
    if [ "$USE_MOCK" = true ]; then
        # Generate mock data
        ITEMS='[
            {"rawProductName":"Blue Dream - 3.5g","rawBrandName":"Tyson 2.0","rawCategory":"Flower","strainType":"HYBRID","price":45.00,"inStock":true,"thcFormatted":"22.5%","sourceUrl":"'$SOURCE_URL'","sourcePlatform":"dutchie","scrapedAt":'$TIMESTAMP'},
            {"rawProductName":"OG Kush Pre-Roll - 1g","rawBrandName":"Cookies","rawCategory":"Pre-Roll","strainType":"INDICA","price":15.00,"inStock":true,"sourceUrl":"'$SOURCE_URL'","sourcePlatform":"dutchie","scrapedAt":'$TIMESTAMP'},
            {"rawProductName":"Live Resin Cart - 0.5g","rawBrandName":"Select","rawCategory":"Vapes","price":40.00,"inStock":true,"sourceUrl":"'$SOURCE_URL'","sourcePlatform":"dutchie","scrapedAt":'$TIMESTAMP'}
        ]'
        log "   ğŸ“¦ Generated 3 mock items"
    else
        # Transform scraped data (browser worker format â†’ ingestion format)
        # Note: This would need proper JSON transformation in production
        ITEMS=$(echo "$SCRAPE_RESULT" | jq -c '[.products[] | {
            rawProductName: .name,
            rawBrandName: (.brand // "Unknown"),
            rawCategory: .category,
            price: ((.price | gsub("[$,]"; "") | tonumber) // 0),
            inStock: (.stock != 0),
            sourceUrl: "'"$SOURCE_URL"'",
            sourcePlatform: "dutchie",
            scrapedAt: '"$TIMESTAMP"'
        }]' 2>/dev/null || echo '[]')
    fi
    
    # Add to results
    if [ "$FIRST" = false ]; then
        RESULTS+=","
    fi
    FIRST=false
    
    RESULTS+='{"retailerId":"'$RETAILER_ID'","items":'$ITEMS',"status":"ok"}'
done

RESULTS+="]"

# Ingest to Convex
log ""
log "ğŸ“¤ Ingesting to Convex..."

INGEST_RESPONSE=$(curl -s -X POST "${CONVEX_URL}/api/mutation" \
    -H "Content-Type: application/json" \
    -H "Authorization: Convex ${CONVEX_DEPLOY_KEY}" \
    -d '{
        "path": "ingestion:ingestScrapedBatch",
        "args": {
            "batchId": "'"$BATCH_ID"'",
            "results": '"$RESULTS"'
        }
    }')

# Parse response
if echo "$INGEST_RESPONSE" | grep -q '"status":"success"'; then
    PROCESSED=$(echo "$INGEST_RESPONSE" | jq -r '.value.totalProcessed // 0')
    FAILED=$(echo "$INGEST_RESPONSE" | jq -r '.value.totalFailed // 0')
    log "âœ… Ingestion complete: $PROCESSED processed, $FAILED failed"
else
    error "Ingestion failed: $INGEST_RESPONSE"
    exit 1
fi

log ""
log "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
log "âœ… Pipeline complete!"
log "   Batch: $BATCH_ID"
log "   Data saved to: $DATA_DIR"
